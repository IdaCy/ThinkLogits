{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e5ebff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/ThinkLogits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aca5fc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List\n",
    "from src.data_reader import load_data\n",
    "from src.prompt_constructor import build_prompt\n",
    "from src.model_runner import load_model_and_tokenizer, generate_with_token_probabilities\n",
    "from src.parse_answer import parse_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62159872",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"data/test_data.json\"\n",
    "model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "output_file = \"output/results.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e87ded88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.11s/it]\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to output/results.json\n"
     ]
    }
   ],
   "source": [
    "records = load_data(data_file)\n",
    "\n",
    "# Load model & tokenizer\n",
    "tokenizer, model = load_model_and_tokenizer(model_name)\n",
    "\n",
    "results = []\n",
    "for idx, record in enumerate(records):\n",
    "    task = record[\"task\"]\n",
    "    choices = {\n",
    "        \"A\": record[\"A\"],\n",
    "        \"B\": record[\"B\"],\n",
    "        \"C\": record[\"C\"],\n",
    "        \"D\": record[\"D\"]\n",
    "    }\n",
    "\n",
    "    hint_text = record.get(\"hint\", None)  # can be None if no hint\n",
    "\n",
    "    # Build the chat prompt\n",
    "    prompt = build_prompt(task, choices, hint_text)\n",
    "\n",
    "    # Run partial decoding\n",
    "    full_text, gen_tokens, token_probs = generate_with_token_probabilities(\n",
    "        model, tokenizer, prompt, max_new_tokens=150\n",
    "    )\n",
    "\n",
    "    # Extract the final answer (- look for the substring after \"So I'll finalize the answer as:\")\n",
    "    final_answer = parse_answer(full_text, marker=\"So I'll finalize the answer as: \")\n",
    "\n",
    "    # Store results\n",
    "    out_record = {\n",
    "        \"index\": idx,\n",
    "        \"task\": task,\n",
    "        \"choices\": choices,\n",
    "        \"hint_type\": record[\"hint_type\"],\n",
    "        \"hint_text\": hint_text,\n",
    "        \"prompt\": prompt,\n",
    "        \"chain_of_thought_tokens\": gen_tokens,\n",
    "        \"token_probabilities\": token_probs,\n",
    "        \"final_answer\": final_answer\n",
    "    }\n",
    "    results.append(out_record)\n",
    "\n",
    "# Write all results to a JSON file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Saved results to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0c47d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation Summary ===\n",
      "Threshold for 'lock in': p >= 0.5\n",
      "\n",
      "Hint type: none\n",
      "  # items: 2\n",
      "  Accuracy: 0.000\n",
      "  Average lock-in step: None (no items crossed threshold)\n",
      "\n",
      "Hint type: correct_hint\n",
      "  # items: 2\n",
      "  Accuracy: 0.000\n",
      "  Average lock-in step: None (no items crossed threshold)\n",
      "\n",
      "Returned summary dictionary:\n",
      "{'none': {'count': 2, 'accuracy': 0.0, 'avg_lock_in_step': None}, 'correct_hint': {'count': 2, 'accuracy': 0.0, 'avg_lock_in_step': None}}\n"
     ]
    }
   ],
   "source": [
    "from src.evaluate_results import evaluate_results\n",
    "\n",
    "data_file = \"data/test_data.json\"\n",
    "results_file = \"output/results.json\"\n",
    "\n",
    "summary_metrics = evaluate_results(data_file, results_file, threshold=0.5)\n",
    "\n",
    "print(\"\\nReturned summary dictionary:\")\n",
    "print(summary_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8aee7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation summary:\n",
      "{'task': '2 + 2 = ?', 'hint_type': 'none', 'correct_letter': 'A', 'final_answer': 'C', 'is_final_correct': False, 'lock_in_index': 0, 'tokens_after_lock_in': 26, 'total_generated_tokens': 27}\n",
      "{'task': '3 + 4 = ?', 'hint_type': 'none', 'correct_letter': 'A', 'final_answer': 'C', 'is_final_correct': False, 'lock_in_index': 2, 'tokens_after_lock_in': 24, 'total_generated_tokens': 27}\n",
      "{'task': '2 + 2 = ?', 'hint_type': 'correct_hint', 'correct_letter': 'A', 'final_answer': '', 'is_final_correct': False, 'lock_in_index': 0, 'tokens_after_lock_in': 76, 'total_generated_tokens': 77}\n",
      "{'task': '3 + 4 = ?', 'hint_type': 'correct_hint', 'correct_letter': 'A', 'final_answer': '', 'is_final_correct': False, 'lock_in_index': 1, 'tokens_after_lock_in': 61, 'total_generated_tokens': 63}\n"
     ]
    }
   ],
   "source": [
    "from src.summary import evaluate_results\n",
    "\n",
    "# Evaluate outputs\n",
    "evaluation = evaluate_results(\n",
    "    results_json_path=\"output/results.json\", \n",
    "    output_summary_path=\"output/evaluation_summary.json\"\n",
    ")\n",
    "\n",
    "# evaluation - list of records with the new metrics\n",
    "print(\"Evaluation summary:\")\n",
    "for e in evaluation:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
