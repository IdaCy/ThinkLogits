{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/ThinkLogits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "\n",
    "from src.main.pipeline import load_model_and_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 11:57:31,596 - INFO - CUDA is available. Using GPU.\n",
      "2025-04-14 11:57:31,598 - INFO - Loading model and tokenizer: deepseek-ai/DeepSeek-R1-Distill-Llama-8B onto cuda\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]\n",
      "2025-04-14 11:57:40,110 - INFO - Model and tokenizer loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "model, tokenizer, model_name, device = load_model_and_tokenizer(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 11:57:40,124 - INFO - Using chat template: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "{instruction}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "2025-04-14 11:57:40,126 - INFO - --- Processing dataset for hint type: sycophancy ---\n",
      "2025-04-14 11:57:40,158 - INFO - Generating completions for sycophancy...\n",
      "2025-04-14 11:57:40,159 - INFO - Using max_new_tokens: 2048\n",
      "2025-04-14 11:57:40,160 - INFO - Processing batch 1/30 (Size: 5, QIDs: 0-4)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 11:58:11,836 - INFO - Processing batch 2/30 (Size: 5, QIDs: 5-9)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 11:58:33,732 - INFO - Processing batch 3/30 (Size: 5, QIDs: 10-14)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 11:59:46,902 - INFO - Processing batch 4/30 (Size: 5, QIDs: 15-19)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:00:59,886 - INFO - Processing batch 5/30 (Size: 5, QIDs: 20-24)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:02:12,832 - INFO - Processing batch 6/30 (Size: 5, QIDs: 25-29)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:02:40,045 - INFO - Processing batch 7/30 (Size: 5, QIDs: 30-34)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:03:53,285 - INFO - Processing batch 8/30 (Size: 5, QIDs: 35-39)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:04:52,698 - INFO - Processing batch 9/30 (Size: 5, QIDs: 40-44)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:05:21,678 - INFO - Processing batch 10/30 (Size: 5, QIDs: 45-49)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:05:59,993 - INFO - Processing batch 11/30 (Size: 5, QIDs: 50-54)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:06:27,557 - INFO - Processing batch 12/30 (Size: 5, QIDs: 55-59)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:07:22,704 - INFO - Processing batch 13/30 (Size: 5, QIDs: 60-64)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:08:14,085 - INFO - Processing batch 14/30 (Size: 5, QIDs: 65-69)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:08:59,001 - INFO - Processing batch 15/30 (Size: 5, QIDs: 70-74)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:09:17,659 - INFO - Processing batch 16/30 (Size: 5, QIDs: 75-79)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:09:39,857 - INFO - Processing batch 17/30 (Size: 5, QIDs: 80-84)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:10:05,287 - INFO - Processing batch 18/30 (Size: 5, QIDs: 85-89)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:10:41,436 - INFO - Processing batch 19/30 (Size: 5, QIDs: 90-94)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:11:13,062 - INFO - Processing batch 20/30 (Size: 5, QIDs: 95-99)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:12:23,377 - INFO - Processing batch 21/30 (Size: 5, QIDs: 100-104)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:12:51,297 - INFO - Processing batch 22/30 (Size: 5, QIDs: 105-109)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:14:04,317 - INFO - Processing batch 23/30 (Size: 5, QIDs: 110-114)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:14:33,280 - INFO - Processing batch 24/30 (Size: 5, QIDs: 115-119)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:15:46,483 - INFO - Processing batch 25/30 (Size: 5, QIDs: 120-124)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:16:06,808 - INFO - Processing batch 26/30 (Size: 5, QIDs: 125-129)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:16:29,711 - INFO - Processing batch 27/30 (Size: 5, QIDs: 130-134)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:16:55,632 - INFO - Processing batch 28/30 (Size: 5, QIDs: 135-139)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:17:33,489 - INFO - Processing batch 29/30 (Size: 5, QIDs: 140-144)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:18:37,108 - INFO - Processing batch 30/30 (Size: 5, QIDs: 145-149)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:19:03,228 - INFO - Results saved to data/sycophancy/completions_DeepSeek-R1-Distill-Llama-8B_with_150.json\n",
      "2025-04-14 12:19:03,229 - INFO - Total processing time: 1283.10 seconds\n"
     ]
    }
   ],
   "source": [
    "src.main.generate_dataset_completions(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    model_name = model_name,\n",
    "    device = device,\n",
    "    hint_types = [\"sycophancy\"],\n",
    "    batch_size = 5,\n",
    "    max_new_tokens = None,\n",
    "    n_questions = 150\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 12:19:03,245 - INFO - Using chat template: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "{instruction}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "2025-04-14 12:19:03,248 - INFO - --- Processing dataset for hint type: induced_urgency ---\n",
      "2025-04-14 12:19:03,286 - INFO - Generating completions for induced_urgency...\n",
      "2025-04-14 12:19:03,287 - INFO - Using max_new_tokens: 2048\n",
      "2025-04-14 12:19:03,288 - INFO - Processing batch 1/30 (Size: 5, QIDs: 0-4)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:20:16,024 - INFO - Processing batch 2/30 (Size: 5, QIDs: 5-9)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:20:49,435 - INFO - Processing batch 3/30 (Size: 5, QIDs: 10-14)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:21:22,209 - INFO - Processing batch 4/30 (Size: 5, QIDs: 15-19)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:22:35,215 - INFO - Processing batch 5/30 (Size: 5, QIDs: 20-24)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:23:07,061 - INFO - Processing batch 6/30 (Size: 5, QIDs: 25-29)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:23:32,301 - INFO - Processing batch 7/30 (Size: 5, QIDs: 30-34)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:24:28,296 - INFO - Processing batch 8/30 (Size: 5, QIDs: 35-39)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:24:56,092 - INFO - Processing batch 9/30 (Size: 5, QIDs: 40-44)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:25:28,740 - INFO - Processing batch 10/30 (Size: 5, QIDs: 45-49)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:25:52,210 - INFO - Processing batch 11/30 (Size: 5, QIDs: 50-54)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:26:34,947 - INFO - Processing batch 12/30 (Size: 5, QIDs: 55-59)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:27:00,178 - INFO - Processing batch 13/30 (Size: 5, QIDs: 60-64)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:28:13,445 - INFO - Processing batch 14/30 (Size: 5, QIDs: 65-69)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:28:47,937 - INFO - Processing batch 15/30 (Size: 5, QIDs: 70-74)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:29:10,573 - INFO - Processing batch 16/30 (Size: 5, QIDs: 75-79)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:29:30,825 - INFO - Processing batch 17/30 (Size: 5, QIDs: 80-84)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:30:12,899 - INFO - Processing batch 18/30 (Size: 5, QIDs: 85-89)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:30:36,378 - INFO - Processing batch 19/30 (Size: 5, QIDs: 90-94)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:30:53,706 - INFO - Processing batch 20/30 (Size: 5, QIDs: 95-99)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:31:55,501 - INFO - Processing batch 21/30 (Size: 5, QIDs: 100-104)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:32:25,967 - INFO - Processing batch 22/30 (Size: 5, QIDs: 105-109)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:33:39,087 - INFO - Processing batch 23/30 (Size: 5, QIDs: 110-114)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:33:56,255 - INFO - Processing batch 24/30 (Size: 5, QIDs: 115-119)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:34:43,130 - INFO - Processing batch 25/30 (Size: 5, QIDs: 120-124)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:35:23,972 - INFO - Processing batch 26/30 (Size: 5, QIDs: 125-129)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:36:36,978 - INFO - Processing batch 27/30 (Size: 5, QIDs: 130-134)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:36:58,964 - INFO - Processing batch 28/30 (Size: 5, QIDs: 135-139)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:37:23,963 - INFO - Processing batch 29/30 (Size: 5, QIDs: 140-144)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:37:45,242 - INFO - Processing batch 30/30 (Size: 5, QIDs: 145-149)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:38:06,951 - INFO - Results saved to data/induced_urgency/completions_DeepSeek-R1-Distill-Llama-8B_with_150.json\n",
      "2025-04-14 12:38:06,953 - INFO - Total processing time: 1143.71 seconds\n"
     ]
    }
   ],
   "source": [
    "src.main.generate_dataset_completions(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    model_name = model_name,\n",
    "    device = device,\n",
    "    hint_types = [\"induced_urgency\"],\n",
    "    batch_size = 5,\n",
    "    max_new_tokens = None,\n",
    "    n_questions = 150\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 12:38:06,964 - INFO - Using chat template: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "{instruction}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "2025-04-14 12:38:06,966 - INFO - --- Processing dataset for hint type: unethical_information ---\n",
      "2025-04-14 12:38:06,997 - INFO - Generating completions for unethical_information...\n",
      "2025-04-14 12:38:06,998 - INFO - Using max_new_tokens: 2048\n",
      "2025-04-14 12:38:06,999 - INFO - Processing batch 1/30 (Size: 5, QIDs: 0-4)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:38:56,166 - INFO - Processing batch 2/30 (Size: 5, QIDs: 5-9)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:39:19,342 - INFO - Processing batch 3/30 (Size: 5, QIDs: 10-14)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:40:32,562 - INFO - Processing batch 4/30 (Size: 5, QIDs: 15-19)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:41:45,620 - INFO - Processing batch 5/30 (Size: 5, QIDs: 20-24)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:42:58,668 - INFO - Processing batch 6/30 (Size: 5, QIDs: 25-29)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:43:26,047 - INFO - Processing batch 7/30 (Size: 5, QIDs: 30-34)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:44:25,456 - INFO - Processing batch 8/30 (Size: 5, QIDs: 35-39)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:45:05,853 - INFO - Processing batch 9/30 (Size: 5, QIDs: 40-44)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:45:30,678 - INFO - Processing batch 10/30 (Size: 5, QIDs: 45-49)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:45:51,033 - INFO - Processing batch 11/30 (Size: 5, QIDs: 50-54)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:47:04,031 - INFO - Processing batch 12/30 (Size: 5, QIDs: 55-59)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-04-14 12:47:28,689 - INFO - Processing batch 13/30 (Size: 5, QIDs: 60-64)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "src.main.generate_dataset_completions(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    model_name = model_name,\n",
    "    device = device,\n",
    "    hint_types = [\"unethical_information\"],\n",
    "    batch_size = 5,\n",
    "    max_new_tokens = None,\n",
    "    n_questions = 150\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
